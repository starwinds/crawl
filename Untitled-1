from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import time
from datetime import datetime

class NaverNewsCrawler:
    def __init__(self):
        self.playwright = sync_playwright().start()
        self.browser = self.playwright.chromium.launch(headless=True)
        self.context = self.browser.new_context()
        self.page = self.context.new_page()

    def search_news(self, keyword, num_articles=10):
        """
        키워드로 네이버 뉴스를 검색하고 최신 뉴스 정보를 반환합니다.
        """
        # 네이버 뉴스 검색 페이지로 이동
        search_url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sort=1"  # sort=1 은 최신순
        self.page.goto(search_url)
        self.page.wait_for_load_state('networkidle')

        # 뉴스 기사 정보 추출
        news_items = []
        while len(news_items) < num_articles:
            # 현재 페이지의 뉴스 항목들을 파싱
            html_content = self.page.content()
            soup = BeautifulSoup(html_content, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                if len(news_items) >= num_articles:
                    break

                try:
                    # 제목과 링크 추출
                    title_elem = article.select_one('a.news_tit')
                    title = title_elem.get_text(strip=True)
                    link = title_elem['href']

                    # 언론사 정보
                    press = article.select_one('a.press').get_text(strip=True)

                    # 요약 정보
                    summary = article.select_one('div.news_dsc').get_text(strip=True)

                    # 시간 정보
                    time_elem = article.select_one('span.info')
                    pub_time = time_elem.get_text(strip=True) if time_elem else "시간 정보 없음"

                    news_items.append({
                        'title': title,
                        'press': press,
                        'summary': summary,
                        'link': link,
                        'published_time': pub_time
                    })
                except Exception as e:
                    print(f"Error parsing article: {e}")
                    continue

            # 더 많은 결과가 필요하면 스크롤
            if len(news_items) < num_articles:
                self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                time.sleep(1)  # 새로운 컨텐츠 로딩 대기

        return news_items[:num_articles]

    def close(self):
        """
        브라우저와 Playwright 인스턴스를 종료합니다.
        """
        self.context.close()
        self.browser.close()
        self.playwright.stop()

def main():
    # 크롤러 사용 예시
    keyword = input("검색할 키워드를 입력하세요: ")
    
    crawler = NaverNewsCrawler()
    try:
        news_items = crawler.search_news(keyword)
        
        print(f"\n'{keyword}' 관련 최신 뉴스 10개:\n")
        for idx, item in enumerate(news_items, 1):
            print(f"[{idx}] {item['title']}")
            print(f"언론사: {item['press']}")
            print(f"시간: {item['published_time']}")
            print(f"요약: {item['summary']}")
            print(f"링크: {item['link']}")
            print("-" * 80 + "\n")
    finally:
        crawler.close()

if __name__ == "__main__":
    main()
